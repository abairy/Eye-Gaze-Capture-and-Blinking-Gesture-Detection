{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from os.path import join\n",
    "import json\n",
    "#from data_utility import image_normalization\n",
    "import random\n",
    "\n",
    "\n",
    "# normalize all data\n",
    "def normalize(data):\n",
    "\n",
    "    print(\"Data normalization...\")\n",
    "    shape = data.shape\n",
    "    data = np.reshape(data, (shape[0], -1))\n",
    "    # scaling\n",
    "    data = data.astype('float32') / 255.\n",
    "    # normalizing\n",
    "    data = data - np.mean(data, axis=0)\n",
    "    print(\"Done.\")\n",
    "    return np.reshape(data, shape)\n",
    "\n",
    "\n",
    "# normalize a single image\n",
    "def image_normalization(img):\n",
    "\n",
    "    img = img.astype('float32') / 255.\n",
    "    img = img - np.mean(img)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "# prepare all data (npz version)\n",
    "def prepare_data(data):\n",
    "    print(\"Data preparing...\")\n",
    "    eye_left, eye_right, face, face_mask, y = data\n",
    "    eye_left = normalize(eye_left)\n",
    "    eye_right = normalize(eye_right)\n",
    "    face = normalize(face)\n",
    "    face_mask = np.reshape(face_mask, (face_mask.shape[0], -1)).astype('float32')\n",
    "    y = y.astype('float32')\n",
    "    print(\"Done.\")\n",
    "    return [eye_left, eye_right, face, face_mask, y]\n",
    "\n",
    "\n",
    "# shuffle data\n",
    "def shuffle_data(data):\n",
    "\n",
    "    idx = np.arange(data[0].shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    for i in list(range(len(data))):\n",
    "        data[i] = data[i][idx]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_npz(file):\n",
    "\n",
    "    print(\"Loading dataset from npz file...\", end='')\n",
    "    npzfile = np.load(file)\n",
    "    print(npzfile.files)\n",
    "\n",
    "    train_eye_left = npzfile[\"train_eye_left\"]\n",
    "    train_eye_right = npzfile[\"train_eye_right\"]\n",
    "    train_face = npzfile[\"train_face\"]\n",
    "    train_face_mask = npzfile[\"train_face_mask\"]\n",
    "    train_y = npzfile[\"train_y\"]\n",
    "    val_eye_left = npzfile[\"val_eye_left\"]\n",
    "    val_eye_right = npzfile[\"val_eye_right\"]\n",
    "    val_face = npzfile[\"val_face\"]\n",
    "    val_face_mask = npzfile[\"val_face_mask\"]\n",
    "    val_y = npzfile[\"val_y\"]\n",
    "    print(\"Done.\")\n",
    "\n",
    "    return [train_eye_left, train_eye_right, train_face, train_face_mask, train_y], [val_eye_left, val_eye_right, val_face, val_face_mask, val_y]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_batch(data, img_ch, img_cols, img_rows):\n",
    "\n",
    "    # useful for debug\n",
    "    save_images = False\n",
    "\n",
    "    # if save images, create the related directory\n",
    "    img_dir = \"images\"\n",
    "    if save_images:\n",
    "        if not os.path.exists(img_dir):\n",
    "            os.makedir(img_dir)\n",
    "\n",
    "    # create batch structures\n",
    "    left_eye_batch = np.zeros(shape=(data[0].shape[0], img_ch, img_cols, img_rows), dtype=np.float32)\n",
    "    right_eye_batch = np.zeros(shape=(data[0].shape[0], img_ch, img_cols, img_rows), dtype=np.float32)\n",
    "    face_batch = np.zeros(shape=(data[0].shape[0], img_ch, img_cols, img_rows), dtype=np.float32)\n",
    "    face_grid_batch = np.zeros(shape=(data[0].shape[0], 1, 25, 25), dtype=np.float32)\n",
    "    y_batch = np.zeros((data[0].shape[0], 2), dtype=np.float32)\n",
    "\n",
    "    # load left eye\n",
    "    for i, img in enumerate(data[0]):\n",
    "        img = cv2.resize(img, (img_cols, img_rows))\n",
    "        if save_images:\n",
    "            cv2.imwrite(join(img_dir, \"left\" + str(i) + \".png\"), img)\n",
    "        img = image_normalization(img)\n",
    "        left_eye_batch[i] = img.transpose(2, 0, 1)\n",
    "\n",
    "    # load right eye\n",
    "    for i, img in enumerate(data[1]):\n",
    "        img = cv2.resize(img, (img_cols, img_rows))\n",
    "        if save_images:\n",
    "            cv2.imwrite(\"images/right\" + str(i) + \".png\", img)\n",
    "        img = image_normalization(img)\n",
    "        right_eye_batch[i] = img.transpose(2, 0, 1)\n",
    "\n",
    "    # load faces\n",
    "    for i, img in enumerate(data[2]):\n",
    "        img = cv2.resize(img, (img_cols, img_rows))\n",
    "        if save_images:\n",
    "            cv2.imwrite(\"images/face\" + str(i) + \".png\", img)\n",
    "        img = image_normalization(img)\n",
    "        face_batch[i] = img.transpose(2, 0, 1)\n",
    "\n",
    "    # load grid faces\n",
    "    for i, img in enumerate(data[3]):\n",
    "        if save_images:\n",
    "            cv2.imwrite(\"images/grid\" + str(i) + \".png\", img)\n",
    "        face_grid_batch[i] = img.reshape((1, img.shape[0], img.shape[1]))\n",
    "\n",
    "    # load labels\n",
    "    for i, labels in enumerate(data[4]):\n",
    "        y_batch[i] = labels\n",
    "\n",
    "    return [right_eye_batch, left_eye_batch, face_batch, face_grid_batch], y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Layer\n",
    "from keras.layers import Input, Conv2D, Dense, Flatten, MaxPool2D, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "class ScaledSigmoid(Layer):\n",
    "    def __init__(self, alpha, beta, **kwargs):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        super(ScaledSigmoid, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ScaledSigmoid, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        return self.alpha / (1 + np.exp(-x / self.beta))\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "\n",
    "# activation functions\n",
    "activation = 'relu'\n",
    "last_activation = 'linear'\n",
    "\n",
    "\n",
    "# eye model\n",
    "def get_eye_model(img_ch, img_cols, img_rows):\n",
    "\n",
    "    eye_img_input = Input(shape=(img_ch, img_cols, img_rows))\n",
    "\n",
    "    h = Conv2D(96, (11, 11), activation=activation,data_format='channels_first')(eye_img_input)\n",
    "    h = MaxPool2D(pool_size=(2, 2))(h)\n",
    "    h = Conv2D(256, (5, 5), activation=activation,data_format='channels_first')(h)\n",
    "    h = MaxPool2D(pool_size=(2, 2))(h)\n",
    "    h = Conv2D(384, (3, 3), activation=activation,data_format='channels_first')(h)\n",
    "    h = MaxPool2D(pool_size=(2, 2))(h)\n",
    "    out = Conv2D(64, (1, 1), activation=activation,data_format='channels_first')(h)\n",
    "\n",
    "    model = Model(inputs=eye_img_input, outputs=out)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# face model\n",
    "def get_face_model(img_ch, img_cols, img_rows):\n",
    "\n",
    "    face_img_input = Input(shape=(img_ch, img_cols, img_rows))\n",
    "\n",
    "    h = Conv2D(96, (11, 11), activation=activation,data_format='channels_first')(face_img_input)\n",
    "    h = MaxPool2D(pool_size=(2, 2))(h)\n",
    "    h = Conv2D(256, (5, 5), activation=activation,data_format='channels_first')(h)\n",
    "    h = MaxPool2D(pool_size=(2, 2))(h)\n",
    "    h = Conv2D(384, (3, 3), activation=activation,data_format='channels_first')(h)\n",
    "    h = MaxPool2D(pool_size=(2, 2))(h)\n",
    "    out = Conv2D(64, (1, 1), activation=activation,data_format='channels_first')(h)\n",
    "\n",
    "    model = Model(inputs=face_img_input, outputs=out)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# final model\n",
    "def get_eye_tracker_model(img_ch, img_cols, img_rows):\n",
    "\n",
    "    # get partial models\n",
    "    eye_net = get_eye_model(img_ch, img_cols, img_rows)\n",
    "    face_net_part = get_face_model(img_ch, img_cols, img_rows)\n",
    "\n",
    "    # right eye model\n",
    "    right_eye_input = Input(shape=(img_ch, img_cols, img_rows))\n",
    "    right_eye_net = eye_net(right_eye_input)\n",
    "\n",
    "    # left eye model\n",
    "    left_eye_input = Input(shape=(img_ch, img_cols, img_rows))\n",
    "    left_eye_net = eye_net(left_eye_input)\n",
    "\n",
    "    # face model\n",
    "    face_input = Input(shape=(img_ch, img_cols, img_rows))\n",
    "    face_net = face_net_part(face_input)\n",
    "\n",
    "    # face grid\n",
    "    face_grid = Input(shape=(1, 25, 25))\n",
    "\n",
    "    # dense layers for eyes\n",
    "    e = concatenate([left_eye_net, right_eye_net])\n",
    "    e = Flatten()(e)\n",
    "    fc_e1 = Dense(128, activation=activation)(e)\n",
    "\n",
    "    # dense layers for face\n",
    "    f = Flatten()(face_net)\n",
    "    fc_f1 = Dense(128, activation=activation)(f)\n",
    "    fc_f2 = Dense(64, activation=activation)(fc_f1)\n",
    "\n",
    "    # dense layers for face grid\n",
    "    fg = Flatten()(face_grid)\n",
    "    fc_fg1 = Dense(256, activation=activation)(fg)\n",
    "    fc_fg2 = Dense(128, activation=activation)(fc_fg1)\n",
    "\n",
    "    # final dense layers\n",
    "    h = concatenate([fc_e1, fc_f2, fc_fg2])\n",
    "    fc1 = Dense(128, activation=activation)(h)\n",
    "    fc2 = Dense(2, activation=last_activation)(fc1)\n",
    "\n",
    "    # final model\n",
    "    final_model = Model(\n",
    "        inputs=[right_eye_input, left_eye_input, face_input, face_grid],\n",
    "        outputs=[fc2])\n",
    "\n",
    "    return final_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import  EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "# generator for data loaded from the npz file\n",
    "def generator_npz(data, batch_size, img_ch, img_cols, img_rows):\n",
    "\n",
    "    while True:\n",
    "        for it in list(range(0, data[0].shape[0], batch_size)):\n",
    "            x, y = load_batch([l[it:it + batch_size] for l in data], img_ch, img_cols, img_rows)\n",
    "            yield x, y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train():\n",
    "\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = '-1'\n",
    "\n",
    "    #todo: manage parameters in main\n",
    "\n",
    "\n",
    "    # train parameters\n",
    "    n_epoch = 100\n",
    "    batch_size = 128\n",
    "    patience = 15\n",
    "\n",
    "    # image parameter\n",
    "    img_cols = 64\n",
    "    img_rows = 64\n",
    "    img_ch = 3\n",
    "\n",
    "    # model\n",
    "    model = get_eye_tracker_model(img_ch, img_cols, img_rows)\n",
    "\n",
    "    # model summary\n",
    "    model.summary()\n",
    "\n",
    "    # weights\n",
    "    # print(\"Loading weights...\",  end='')\n",
    "    # weights_path = \"weights/weights.003-4.05525.hdf5\"\n",
    "    # model.load_weights(weights_path)\n",
    "    # print(\"Done.\")\n",
    "\n",
    "    # optimizer\n",
    "    sgd = SGD(lr=1e-1, decay=5e-4, momentum=9e-1, nesterov=True)\n",
    "    adam = Adam(lr=1e-3)\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer=adam, loss='mse')\n",
    "\n",
    "    # data\n",
    "    # todo: parameters not hardocoded\n",
    "\n",
    "    train_data, val_data = load_data_from_npz('eye_tracker_train_and_val.npz')\n",
    "\n",
    "    # debug\n",
    "    # x, y = load_batch([l[0:batch_size] for l in train_data], img_ch, img_cols, img_rows)\n",
    "    # x, y = load_batch_from_names(train_names[0:batch_size], dataset_path, img_ch, img_cols, img_rows)\n",
    "\n",
    "    # last dataset checks\n",
    "\n",
    "    print(\"train data sources of size: {} {} {} {} {}\".format(\n",
    "        train_data[0].shape[0], train_data[1].shape[0], train_data[2].shape[0],\n",
    "        train_data[3].shape[0], train_data[4].shape[0]))\n",
    "    print(\"validation data sources of size: {} {} {} {} {}\".format(\n",
    "        val_data[0].shape[0], val_data[1].shape[0], val_data[2].shape[0],\n",
    "        val_data[3].shape[0], val_data[4].shape[0]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model.fit_generator(\n",
    "        generator=generator_npz(train_data, batch_size, img_ch, img_cols, img_rows),\n",
    "        steps_per_epoch=(train_data[0].shape[0])/batch_size,\n",
    "        epochs=n_epoch,\n",
    "        verbose=1,\n",
    "        validation_data=generator_npz(val_data, batch_size, img_ch, img_cols, img_rows),\n",
    "        validation_steps=(val_data[0].shape[0])/batch_size,\n",
    "        callbacks=[EarlyStopping(patience=patience),\n",
    "                   ModelCheckpoint(\"weights/weights.{epoch:03d}-{val_loss:.5f}.hdf5\", save_best_only=True)\n",
    "                   ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def test_small():\n",
    "    # os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = -1\n",
    "\n",
    "    dataset_path = \"\"\n",
    "    print(\"Dataset: {}\".format(dataset_path))\n",
    "\n",
    "    weights_path = \"\"\n",
    "    print(\"Weights: {}\".format(weights_path))\n",
    "\n",
    "    # image parameter\n",
    "    img_cols = 64\n",
    "    img_rows = 64\n",
    "    img_ch = 3\n",
    "\n",
    "    # test parameter\n",
    "    batch_size = 128\n",
    "\n",
    "    # model\n",
    "    model = get_eye_tracker_model(img_ch, img_cols, img_rows)\n",
    "\n",
    "    # model summary\n",
    "    model.summary()\n",
    "\n",
    "    # weights\n",
    "    print(\"Loading weights...\")\n",
    "    model.load_weights(weights_path)\n",
    "\n",
    "    # data\n",
    "    train_data, val_data = load_data_from_npz(dataset_path)\n",
    "\n",
    "    print(\"Loading testing data...\")\n",
    "    x, y = load_batch([l[:] for l in val_data], img_ch, img_cols, img_rows)\n",
    "    print(\"Done.\")\n",
    "\n",
    "    predictions = model.predict(x=x, batch_size=batch_size, verbose=1)\n",
    "\n",
    "    # print and analyze predictions\n",
    "    err_x = []\n",
    "    err_y = []\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        print(\"PR: {} {}\".format(prediction[0], prediction[1]))\n",
    "        print(\"GT: {} {} \\n\".format(y[i][0], y[i][1]))\n",
    "\n",
    "        err_x.append(abs(prediction[0] - y[i][0]))\n",
    "        err_y.append(abs(prediction[1] - y[i][1]))\n",
    "\n",
    "    # mean absolute error\n",
    "    mae_x = np.mean(err_x)\n",
    "    mae_y = np.mean(err_y)\n",
    "\n",
    "    # standard deviation\n",
    "    std_x = np.std(err_x)\n",
    "    std_y = np.std(err_y)\n",
    "\n",
    "    # final results\n",
    "    print(\"MAE: {} {} ({} samples)\".format(mae_x, mae_y, len(y)))\n",
    "    print(\"STD: {} {} ({} samples)\".format(std_x, std_y, len(y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
